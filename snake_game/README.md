# ğŸ AnÃ¡lisis de Implementaciones del Juego SNAKE

## ğŸ“Œ IntroducciÃ³n

El juego **SNAKE** es un clÃ¡sico de los videojuegos, conocido por su mecÃ¡nica sencilla pero desafiante. Fue creado originalmente en 1976 por **Gremlin Industries** como un juego arcade llamado *Blockade*. Sin embargo, la versiÃ³n mÃ¡s popular fue la que apareciÃ³ en los telÃ©fonos Nokia en 1997, convirtiÃ©ndose en un fenÃ³meno mundial.

A lo largo del tiempo, se han desarrollado mÃºltiples versiones y enfoques para implementarlo, desde algoritmos bÃ¡sicos hasta tÃ©cnicas avanzadas de optimizaciÃ³n e inteligencia artificial.

Â¿Y si le pedimos a un LLM que nos facilite un cÃ³digo en `HTML` para que implemente este juego? Â¿Y si se lo pedimos a varios LLMs y valoramos la capacidad resolutiva de cada uno de ellos ante el mismo `prompt` y con una sola oportunidad?

## ğŸ” MetodologÃ­a del Experimento

En este experimento, evaluamos las capacidades de diferentes modelos de lenguaje (LLMs) para generar cÃ³digo `HTML` para un juego bÃ¡sico como el *snake*, con el objetivo de determinar su capacidad para facilitar tareas de cÃ³digo y agilizar el proceso de desarrollo, permitiendo a los desarrolladores centrarse en aspectos mÃ¡s complejos y creativos del proyecto.

Para evaluar el rendimiento de diferentes modelos de lenguaje en la generaciÃ³n de cÃ³digo, se utilizÃ³ un mismo `prompt` detallado para todos los modelos. El `prompt` proporcionado fue el siguiente:

> **Genera un juego Snake utilizando HTML, CSS y JavaScript.**
>
> **(1)** La interfaz debe incluir un Ã¡rea de juego dentro de un recuadro donde se moverÃ¡ la serpiente y, debajo, un botÃ³n "PLAY" para iniciar el juego. Incluye un tÃ­tulo multicolor tipo arcade pixelado encima del recuadro que indique "SNAKE GAME", cada letra serÃ¡ de un color.
>
> **(2)** La serpiente iniciarÃ¡ con un solo segmento y se moverÃ¡ en respuesta a las flechas del teclado.
>
> **(3)** A medida que consuma premios generados aleatoriamente en la pantalla, crecerÃ¡ en longitud.
>
> **(4)** Condiciones de finalizaciÃ³n:
> - La serpiente alcanza una longitud de 20.
> - Choca con las paredes del Ã¡rea de juego.
> - Choca consigo misma.
>
> **(5)** Cuando la serpiente colisione, cambiarÃ¡ de color verde a rojo, aparecerÃ¡ un mensaje "GAME OVER", y el usuario podrÃ¡ elegir entre reiniciar el juego o salir.
>
> **(6)** Extras a considerar para mejorar la experiencia:
> - Velocidad progresiva: opciÃ³n para aumentar ligeramente la velocidad conforme la serpiente crece.
> - EstÃ©tica: se recomienda un diseÃ±o moderno con CSS para mejorar la experiencia visual.
> - Estructura del cÃ³digo: utilizar una clase en JavaScript para manejar la lÃ³gica del juego de forma organizada.
> - Efectos y animaciones: agregar una animaciÃ³n de movimiento fluido para mejorar la experiencia.
>
> **(7)** Genera todo el cÃ³digo dentro del HTML.

---

## ğŸ” AnÃ¡lisis de modelos y su capacidad generativa

Diferentes modelos de lenguaje pueden responder de manera variable a un mismo `prompt` debido a mÃºltiples factores:

- **Conocimiento previo del juego:** Algunos modelos pueden haber sido entrenados con datos que incluyen implementaciones de SNAKE, lo que podrÃ­a llevar a un cierto grado de *overfitting*, generando cÃ³digo basado en ejemplos conocidos en lugar de interpretar el `prompt` desde cero.
- **Capacidad de razonamiento:** Modelos mÃ¡s avanzados en razonamiento pueden descomponer mejor la tarea en sus partes fundamentales, asegurando una implementaciÃ³n mÃ¡s estructurada y sin omitir detalles importantes.
- **OptimizaciÃ³n del cÃ³digo:** Algunos modelos tienden a generar cÃ³digo mÃ¡s modular y limpio, mientras que otros pueden producir soluciones funcionales pero menos organizadas.
- **Capacidad de manejo de instrucciones:** Modelos con mejor alineaciÃ³n hacia tareas complejas pueden seguir el `prompt` de manera mÃ¡s estricta, mientras que otros pueden omitir ciertos detalles o interpretarlos de manera distinta.

---

## ğŸ“Š Comparativa entre modelos de lenguaje

| Modelo LLM  | Aspecto de la App | Jugabilidad | Requiere Mejoras | InterpretaciÃ³n del Prompt |
| ----------- | ----------------- | ----------- | ---------------- |------------------------| 
| GPT-4       | â­â­â­â­              | âœ…           | NO                | â­â­â­â­ |               
| Claude 3.5  | â­â­â­â­               | âœ…           | NO                | â­â­â­â­ |  
| DeepSeek R1 | â­                | âŒ           | YES                | â­ |                    
| Gemini 2.0  | â­â­               | âœ…           | SOME                | â­â­â­ | 
| Llama 3.3   | â­â­â­â­                | âœ…          | SOME                | â­â­â­ | 
| Phi 4       | â­â­â­               | âœ…           | âŒ                | â­â­â­ | 
| Qwen 2.5    | â­                | âŒ         | YES                | â­ | 

---

## ğŸ“¸ Screenshots

| GPT-4 | Claude 3.5 | DeepSeek R1 |
|:-----:|:----------:|:---------:|
| ![GPT-4](../images/GPT-4o.png) | ![Claude](../images/Claude_3.5.png) | ![DeepSeek](../images/DeepSeek_R1.png) |

| Gemini 2.0 | Llama 3.3 | Phi 4 | Qwen 2.5 |
|:-----:|:----------:|:---------:|:---------:|
| ![Gemini](../images/Gemini_2.0_Flash.png) | ![Llama](../images/Llama3.3-70b.png) | ![Phi4](../images/Phi4.png) | ![Qwen](../images/Phi.png) | ![Phi](../images/Qwen2.5-Coder-32b.png) |

---

## ğŸ“œ ConclusiÃ³n ğŸ¤”

El juego **SNAKE** ofrece mÃºltiples enfoques de implementaciÃ³n, desde simples bucles hasta complejas redes neuronales. Cada soluciÃ³n tiene sus ventajas y desafÃ­os, y su elecciÃ³n depende del contexto de aplicaciÃ³n.

En este experimento, se ha analizado la influencia de distintos **LLMs** en la generaciÃ³n de cÃ³digo, permitiendo comparar su capacidad para optimizar, estructurar y mejorar las soluciones propuestas. Se ha evidenciado que grandes modelos como **GPT-4** y **Claude 3.5** son los mÃ¡s destacados en tÃ©rminos de capacidad para generar cÃ³digo `HTML` para juegos, con una excelente interpretaciÃ³n del prompt y una jugabilidad efectiva ğŸ®.

Por otro lado, modelos que han sido entrenados con datos de cÃ³digo pueden generar soluciones preexistentes en lugar de crear una nueva implementaciÃ³n basada en el prompt, lo que puede derivar en un cierto sesgo de *overfitting*. Evaluar estas herramientas en escenarios prÃ¡cticos ayuda a entender sus beneficios y limitaciones en el desarrollo de software.

Un prompt mÃ¡s elaborado y desde luego varias interacciones con estos modelos, hubieran dado un resultado mÃ¡s elaborado. En cualquier caso, el uso de estos modelos pueden servir como punto base para desarrollos mÃ¡s complejos pero sin olvidar de la importancia de la interpretabilidad del cÃ³digo.

---
## ğŸ’» Archivos HTML

A continuaciÃ³n, encontrarÃ¡s los enlaces a los archivos HTML generados para cada implementaciÃ³n del juego SNAKE. Haz clic en cada enlace para abrir los archivos en una nueva pestaÃ±a del navegador:

- <a href="snake_game_by_GPT-4o.html" target="_blank">Juego SNAKE - ImplementaciÃ³n GPT-4o</a>


---
## ğŸ”— Referencias

- [Historia del juego Snake - Wikipedia](https://es.wikipedia.org/wiki/Snake_(videojuego))

---

Â¡Espero que este anÃ¡lisis te haya resultado interesante! ğŸš€
